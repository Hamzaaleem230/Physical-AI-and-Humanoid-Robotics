---
id: weekly-roadmap
title: Weekly Roadmap (Weeks 1-13)
slug: /weekly-roadmap
---

# Weekly Roadmap (Weeks 1–13)

This suggested weekly roadmap is designed to guide you through the "Physical AI and Humanoid Robotics" book over a typical 13-week academic semester. It assumes approximately 8-12 hours of engagement per week, including reading, coding, and project work. Adjust this schedule to fit your own pace and learning style.

:::note Flexibility is Key
This roadmap is a suggestion, not a rigid mandate. Feel free to accelerate through familiar topics or spend more time on challenging concepts. The goal is deep understanding, not just completion.
:::

## Module 1: The Robotic Nervous System (ROS 2)

**Goal:** Establish foundational ROS 2 communication, architecture, and basic humanoid control.

| Week | Chapter(s) Covered                                              | Learning Objectives                                                                                                                                                                                                                                          | Practical Work / Mini-Project                                                                                                                                                                                                                         |
| :--- | :-------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1    | *   Preface & Frontmatter                                     *   What is Physical AI?                                      *   ROS 2 Architecture: Nodes, Topics, Services, Actions | *   Understand the motivation and scope of Physical AI.                                     *   Grasp core ROS 2 concepts (nodes, topics, services, actions).                                     *   Install ROS 2 Humble and verify setup. | *   Set up ROS 2 Humble development environment.                                     *   Run basic ROS 2 `talker`/`listener` examples. |
| 2    | *   Building ROS 2 Packages with Python (`rclpy`)                 *   Launch Files, Parameters, TF2                               | *   Create and build ROS 2 Python packages.                                     *   Utilize launch files for system orchestration.                                     *   Manage parameters and understand `tf2` for coordinate transformations. | *   Create a custom ROS 2 Python package.                                     *   Implement a simple publisher/subscriber in Python.                                     *   Practice using `ros2 launch` and `ros2 param` commands. |
| 3    | *   URDF for Humanoids (Links, Joints, Transmissions)             *   Motor Commands, Sensors, Control Loops                      *   Mini Project: Simple Humanoid ROS Controller | *   Model humanoid robot kinematics using URDF.                                     *   Understand motor command generation and sensor data interpretation.                                     *   Implement basic control loops for robot joints.                                     *   **Module 1 Mini-Project: Develop a basic ROS 2 controller for a simulated humanoid.** | *   Create a simple URDF model (e.g., a single arm).                                     *   Implement a ROS 2 node to send motor commands and read simulated sensor data.                                     *   Complete the "Simple Humanoid ROS Controller" mini-project. |

## Module 2: The Digital Twin (Gazebo & Unity)

**Goal:** Build and interact with high-fidelity virtual models of the humanoid robot and its environment.

| Week | Chapter(s) Covered                                              | Learning Objectives                                                                                                                                                                                                                                          | Practical Work / Mini-Project                                                                                                                                                                                                                         |
| :--- | :-------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 4    | *   Gazebo Setup & Physics Engine                               *   URDF to SDF Conversion                                      *   Sensor Simulation (LiDAR, IMU, Depth Camera) | *   Set up Gazebo and understand its physics engine.                                     *   Convert URDF models to SDF.                                     *   Configure and use simulated sensors. | *   Install Gazebo and verify installation.                                     *   Launch a simple Gazebo world.                                     *   Load a humanoid URDF into Gazebo. |
| 5    | *   Collisions, Dynamics & Balance Simulation                     *   Unity for High-Fidelity Rendering                             *   ROS 2 Integration with Simulation                             *   Mini Project: Humanoid Walking + Sensor Visualization | *   Model collisions and dynamics in simulation.                                     *   Utilize Unity for advanced visualization.                                     *   Integrate ROS 2 with Gazebo and Unity.                                     *   **Module 2 Mini-Project: Simulate a humanoid walking and visualize its sensor data.** | *   Refine humanoid model for collision and dynamic properties.                                     *   Set up Unity for robotics visualization.                                     *   Complete the "Humanoid Walking + Sensor Visualization" mini-project. |

## Module 3: The AI-Robot Brain (NVIDIA Isaac Platform)

**Goal:** Teach advanced perception, navigation, and control using the NVIDIA Isaac ecosystem.

| Week | Chapter(s) Covered                                              | Learning Objectives                                                                                                                                                                                                                                          | Practical Work / Mini-Project                                                                                                                                                                                                                         |
| :--- | :-------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 6    | *   Isaac Sim & Omniverse Introduction                          *   Synthetic Data Generation for Vision Models                   | *   Understand the Isaac Sim and Omniverse ecosystem.                                     *   Generate synthetic data for training AI models. | *   Install Isaac Sim and run basic examples.                                     *   Set up a synthetic data generation pipeline for a simple object. |
| 7    | *   Isaac ROS: VSLAM, Perception & Navigation                     *   Nav2 for Humanoid Locomotion                                  | *   Utilize Isaac ROS for hardware-accelerated VSLAM, perception, and navigation.                                     *   Implement Nav2 for autonomous humanoid locomotion. | *   Run an Isaac ROS VSLAM example in Isaac Sim.                                     *   Configure Nav2 for a simulated humanoid. |
| 8    | *   Reinforcement Learning for Control                          *   Sim-to-Real Transfer Design                                   *   Mini Project: Isaac VSLAM + Navigation Pipeline | *   Apply RL techniques for learning complex control policies.                                     *   Design strategies for successful sim-to-real transfer.                                     *   **Module 3 Mini-Project: Build an Isaac-based VSLAM and navigation pipeline.** | *   Implement a basic RL agent for a simple control task.                                     *   Complete the "Isaac VSLAM + Navigation Pipeline" mini-project. |

## Module 4: Vision-Language-Action (VLA)

**Goal:** Integrate LLM-based planning with robotic control for intuitive, voice-controlled robot operation.

| Week | Chapter(s) Covered                                              | Learning Objectives                                                                                                                                                                                                                                          | Practical Work / Mini-Project                                                                                                                                                                                                                         |
| :--- | :-------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 9    | *   Whisper Voice Commands Integration                          *   LLM Planning: Natural Language → ROS 2 Tasks                  | *   Integrate OpenAI Whisper for voice command recognition.                                     *   Understand LLM-based planning to generate robot tasks from natural language. | *   Set up Whisper for voice-to-text conversion.                                     *   Experiment with LLM prompts for generating simple robotic actions. |
| 10   | *   Multimodal Interaction (Speech, Vision, Gesture)            *   VLA Control Graphs for Humanoids                              | *   Explore combining speech, vision, and gesture for human-robot interaction.                                     *   Design VLA control graphs for complex humanoid behaviors. | *   Integrate vision and speech for simple interactive commands.                                     *   Develop a basic VLA control graph for a defined task. |
| 11   | *   Full Loop: Voice → Plan → Navigate → Perceive → Manipulate | *   Integrate all VLA components into a complete perception-to-action loop. | *   Assemble the full VLA pipeline components.                                     *   Test end-to-end voice control for a simple task. |
| 12   | *   Capstone Project: Autonomous Humanoid Robot                 | *   Apply all book concepts to build an autonomous, voice-controlled humanoid robot.                                     *   Integrate planning, navigation, perception, and manipulation.                                     *   Refine and validate the complete system. | *   **Complete the Capstone Project: Develop and demonstrate an autonomous humanoid robot.**                                     *   Prepare for final project presentation/demonstration. |

## Week 13: Review and Beyond

| Week | Activity                                                        | Description                                                                                                                                                                                                                                          |
| :--- | :-------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 13   | *   Review & Consolidation                                      *   Backmatter Exploration                                        *   Further Learning & Research | *   Revisit challenging concepts and solidify understanding.                                     *   Explore the provided glossaries, references, and assessment criteria.                                     *   Identify areas for continued learning and research in physical AI and humanoid robotics. | *   Refactor capstone project code for clarity and efficiency.                                     *   Explore advanced topics or alternative technologies mentioned in the book. |